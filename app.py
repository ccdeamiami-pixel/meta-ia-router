import streamlit as st
from openai import OpenAI
import urllib.parse
import speech_recognition as sr

# --- CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(
    page_title="Meta-IA Router",
    page_icon="üß†",
    layout="centered",
    initial_sidebar_state="collapsed"
)

st.title("üß† Meta-IA Router")
st.caption("La mejor IA del mercado, elegida para ti.")

# --- CONFIGURACI√ìN API ---
api_key = st.secrets.get("OPENROUTER_API_KEY")

if not api_key:
    with st.sidebar:
        st.header("‚öôÔ∏è Sistema")
        api_key = st.text_input("API Key (OpenRouter)", type="password")
        if not api_key:
            st.warning("‚ö†Ô∏è Modo Local: Ingresa tu API Key.")
            st.stop()
else:
    st.sidebar.success("‚úÖ Sistema Conectado")

# --- CLIENTE ---
client = OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

# --- HISTORIAL ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- L√ìGICA DE ROUTING ---
def select_best_model(user_query):
    query = user_query.lower()
    
    if any(word in query for word in ["imagen", "foto", "dibuja", "logo", "creativo visual", "dragon", "gato"]):
        return "image"
    elif any(word in query for word in ["c√≥digo", "python", "javascript", "programar", "bug", "script", "funci√≥n"]):
        return "code"
    else:
        return "text"

# --- ENTRADA POR VOZ O TEXTO ---
prompt = ""

# 1. Opci√≥n Voz (Nuevo!)
st.write("üéôÔ∏è Dicta tu consulta aqu√≠:")
audio_file = st.audio_input("Grabar audio...")

if audio_file:
    with st.spinner("Escuchando y transcribiendo..."):
        recognizer = sr.Recognizer()
        with sr.AudioFile(audio_file) as source:
            audio_data = recognizer.record(source)
            try:
                # Usamos Google Web Speech API (Gratuito)
                text_from_voice = recognizer.recognize_google(audio_data, language="es-ES")
                st.success(f"‚úÖ Escuch√©: **{text_from_voice}**")
                prompt = text_from_voice
            except sr.UnknownValueError:
                st.error("No te entend√≠ bien, intenta escribir.")
            except sr.RequestError:
                st.error("Error conectando con el servicio de voz.")

# 2. Opci√≥n Texto (Si no hubo voz, usa esto)
if not prompt:
    prompt = st.chat_input("Escribe tu consulta...")

# --- EJECUCI√ìN ---
if prompt:
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    mode = select_best_model(prompt)

    with st.chat_message("assistant"):
        
        if mode == "image":
            st.caption("üé® Generando imagen con Pollinations AI...")
            
            encoded_prompt = urllib.parse.quote(prompt)
            image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1024&height=1024&nologo=true&seed=random"
            
            try:
                st.image(image_url, caption=f"Prompt: {prompt}")
            except:
                st.markdown(f"### üñºÔ∏è Tu Imagen")
                st.markdown(f"[Ver imagen]({image_url})")
            
            full_response = "Imagen generada."
            
        else:
            # TEXTO / C√ìDIGO
            full_response = ""
            message_placeholder = st.empty()
            
            model_choice = "openai/gpt-4o" if mode == "text" else "anthropic/claude-3.5-sonnet"
            icon = "‚ö°" if mode == "text" else "üíª"
            
            st.caption(f"{icon} {model_choice}")
            
            stream = client.chat.completions.create(
                model=model_choice,
                messages=[{"role": "system", "content": "Eres un asistente √∫til."}, {"role": "user", "content": prompt}],
                stream=True,
                max_tokens=800
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "‚ñå")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
